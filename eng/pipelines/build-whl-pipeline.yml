name: build-whl-pipeline

trigger:
  branches:
    include:
      - main

schedules:
  - cron: "30 1 * * *"
    displayName: Daily run at 07:00 AM IST
    branches:
      include:
        - main
    always: true

jobs:
# - job: BuildWindowsWheels
#   # Use the latest Windows image for building
#   pool:
#     vmImage: 'windows-latest'
#   displayName: 'Build Windows -'
#   # Strategy matrix to build all combinations
#   strategy:
#     matrix:
#       # Python 3.10 (only x64)
#       py310_x64:
#         pythonVersion: '3.10'       # Host Python version
#         shortPyVer: '310'           # Used in filenames like cp310
#         architecture: 'x64'         # Host Python architecture
#         targetArch: 'x64'           # Target architecture to pass to build.bat

#       # Python 3.11
#       py311_x64:
#         pythonVersion: '3.11'       # Host Python version
#         shortPyVer: '311'           # Used in filenames like cp311
#         architecture: 'x64'         # Host Python architecture
#         targetArch: 'x64'           # Target architecture to pass to build.bat
#       py311_arm64:
#         pythonVersion: '3.11'
#         shortPyVer: '311'
#         architecture: 'x64'         # No arm64 Python, use x64 host
#         targetArch: 'arm64'

#       # Python 3.12
#       py312_x64:
#         pythonVersion: '3.12'
#         shortPyVer: '312'
#         architecture: 'x64'
#         targetArch: 'x64'
#       py312_arm64:
#         pythonVersion: '3.12'
#         shortPyVer: '312'
#         architecture: 'x64'
#         targetArch: 'arm64'

#       # Python 3.13
#       py313_x64:
#         pythonVersion: '3.13'
#         shortPyVer: '313'
#         architecture: 'x64'
#         targetArch: 'x64'
#       py313_arm64:
#         pythonVersion: '3.13'
#         shortPyVer: '313'
#         architecture: 'x64'
#         targetArch: 'arm64'

#   steps:
#     # Use correct Python version and architecture for the current job
#     - task: UsePythonVersion@0
#       inputs:
#         versionSpec: '$(pythonVersion)'
#         architecture: '$(architecture)'
#         addToPath: true
#       displayName: 'Use Python $(pythonVersion) ($(architecture))'

#     # Install required packages: pip, CMake, pybind11
#     - script: |
#         python -m pip install --upgrade pip
#         pip install -r requirements.txt
#         pip install cmake pybind11
#       displayName: 'Install dependencies'

#       # Start LocalDB instance
#     - powershell: |
#         sqllocaldb create MSSQLLocalDB
#         sqllocaldb start MSSQLLocalDB
#       displayName: 'Start LocalDB instance'

#     # Create database and user
#     - powershell: |
#         sqlcmd -S "(localdb)\MSSQLLocalDB" -Q "CREATE DATABASE TestDB"
#         sqlcmd -S "(localdb)\MSSQLLocalDB" -Q "CREATE LOGIN testuser WITH PASSWORD = '$(DB_PASSWORD)'"
#         sqlcmd -S "(localdb)\MSSQLLocalDB" -d TestDB -Q "CREATE USER testuser FOR LOGIN testuser"
#         sqlcmd -S "(localdb)\MSSQLLocalDB" -d TestDB -Q "ALTER ROLE db_owner ADD MEMBER testuser"
#       displayName: 'Setup database and user'
#       env:
#         DB_PASSWORD: $(DB_PASSWORD)

#     - task: DownloadPipelineArtifact@2
#       condition: eq(variables['targetArch'], 'arm64')
#       inputs:
#         buildType: 'specific'
#         project: '$(System.TeamProject)'
#         definition: 2162
#         buildVersionToDownload: 'latest'
#         artifactName: 'mssql-python-arm64-libs'
#         targetPath: '$(Build.SourcesDirectory)\mssql_python\pybind\python_libs\arm64'
#       displayName: 'Download ARM64 Python libs from latest successful run on branches'

#     # Build the PYD file by calling build.bat
#     - script: |
#         echo "Python Version: $(pythonVersion)"
#         echo "Short Tag: $(shortPyVer)"
#         echo "Architecture: Host=$(architecture), Target=$(targetArch)"

#         cd "$(Build.SourcesDirectory)\mssql_python\pybind"

#         REM Optional: override lib path if building for ARM64 since we cannot install arm64 python on x64 host
#         if "$(targetArch)"=="arm64" (
#           echo Using arm64-specific Python library...
#           set CUSTOM_PYTHON_LIB_DIR=$(Build.SourcesDirectory)\mssql_python\pybind\python_libs\arm64
#         )

#         REM Call build.bat to build the PYD file
#         call build.bat $(targetArch)

#         REM Calling keep_single_arch.bat to remove ODBC libs of other architectures
#         call keep_single_arch.bat $(targetArch)

#         cd ..\..
#       displayName: 'Build PYD for $(targetArch)'
#       continueOnError: false

#     # Run pytests before packaging
#     - powershell: |
#         Write-Host "Running pytests to validate bindings"
#         if ("$(targetArch)" -eq "arm64") {
#           Write-Host "Skipping pytests on Windows ARM64"
#         } else {
#           python -m pytest -v
#         }
#       displayName: 'Run pytests'
#       env:
#         DB_CONNECTION_STRING: 'Server=(localdb)\MSSQLLocalDB;Database=TestDB;Uid=testuser;Pwd=$(DB_PASSWORD);TrustServerCertificate=yes'

#     # Copy the built .pyd file to staging folder for artifacts
#     - task: CopyFiles@2
#       inputs:
#         SourceFolder: '$(Build.SourcesDirectory)\mssql_python\pybind\build\$(targetArch)\py$(shortPyVer)\Release'
#         Contents: 'ddbc_bindings.cp$(shortPyVer)-*.pyd'
#         TargetFolder: '$(Build.ArtifactStagingDirectory)\ddbc-bindings\windows'
#       displayName: 'Place PYD file into artifacts directory'

#     # Copy the built .pdb files to staging folder for artifacts
#     - task: CopyFiles@2
#       inputs:
#         SourceFolder: '$(Build.SourcesDirectory)\mssql_python\pybind\build\$(targetArch)\py$(shortPyVer)\Release'
#         Contents: 'ddbc_bindings.cp$(shortPyVer)-*.pdbs'
#         TargetFolder: '$(Build.ArtifactStagingDirectory)\all-pdbs'
#       displayName: 'Place PDB file into artifacts directory'

#     # Build wheel package for the current architecture
#     - script: |
#         python -m pip install --upgrade pip
#         pip install wheel setuptools
#         set ARCHITECTURE=$(targetArch)
#         python setup.py bdist_wheel
#       displayName: 'Build wheel package for Python $(pythonVersion) ($(targetArch))'
    
#     # Copy the wheel file to the artifacts
#     - task: CopyFiles@2
#       inputs:
#         SourceFolder: '$(Build.SourcesDirectory)\dist'
#         Contents: '*.whl'
#         TargetFolder: '$(Build.ArtifactStagingDirectory)\dist'
#       displayName: 'Collect wheel package'    

#     # Publish the collected .pyd file(s) as build artifacts
#     - task: PublishBuildArtifacts@1
#       condition: succeededOrFailed()
#       inputs:
#         PathtoPublish: '$(Build.ArtifactStagingDirectory)\ddbc-bindings'
#         ArtifactName: 'mssql-python-ddbc-bindings'
#         publishLocation: 'Container'
#       displayName: 'Publish all PYDs as artifacts'

#     # Publish the python arm64 libraries as build artifacts for next builds if ARM64
#     # We publish them only for ARM64 builds since we cannot install arm64 Python on x64 host
#     # This allows us to reuse the libraries in future ARM64 builds
#     # Publishing will retain the libraries in the build artifacts
#     - task: PublishBuildArtifacts@1
#       condition: eq(variables['targetArch'], 'arm64')
#       inputs:
#         PathtoPublish: '$(Build.SourcesDirectory)\mssql_python\pybind\python_libs\arm64'
#         ArtifactName: 'mssql-python-arm64-libs'
#         publishLocation: 'Container'
#       displayName: 'Publish arm64 libs as artifacts'
    
#     # Publish the collected wheel file(s) as build artifacts
#     - task: PublishBuildArtifacts@1
#       condition: succeededOrFailed()
#       inputs:
#         PathtoPublish: '$(Build.ArtifactStagingDirectory)\dist'
#         ArtifactName: 'mssql-python-wheels-dist'
#         publishLocation: 'Container'
#       displayName: 'Publish all wheels as artifacts'

# - job: BuildMacOSWheels
#   # Use the latest macOS image for building
#   pool:
#     vmImage: 'macos-latest'
#   # Display name for the job in Azure DevOps UI
#   displayName: 'Build macOS - '
#   strategy:
#     matrix:
#       # Python 3.13 (universal2 for both arm64 and x86_64)
#       py313_universal2:
#         pythonVersion: '3.13'
#         shortPyVer: '313'
#         # Always use universal2 for macOS
#         targetArch: 'universal2'
      
#       # Python 3.12 (universal2 for both arm64 and x86_64)
#       py312_universal2:
#         pythonVersion: '3.12'
#         shortPyVer: '312'
#         targetArch: 'universal2'

#       # Python 3.11 (universal2 for both arm64 and x86_64)
#       py311_universal2:
#         pythonVersion: '3.11'
#         shortPyVer: '311'
#         targetArch: 'universal2'
      
#       # Python 3.10 (universal2 for both arm64 and x86_64)
#       py310_universal2:
#         pythonVersion: '3.10'
#         shortPyVer: '310'
#         targetArch: 'universal2'

#   steps:
#     # Use correct Python version and architecture for the current job
#     - task: UsePythonVersion@0
#       inputs:
#         versionSpec: '$(pythonVersion)'
#         addToPath: true
#       displayName: 'Use Python $(pythonVersion) (Universal2)'

#     # Install CMake on macOS
#     - script: |
#         brew update
#         brew install cmake
#       displayName: 'Install CMake'

#     # Install required packages: pip, CMake, pybind11
#     - script: |
#         python -m pip install --upgrade pip
#         pip install -r requirements.txt
#         pip install cmake pybind11
#       displayName: 'Install dependencies'

#     # Build the .so file by calling build.sh
#     - script: |
#         echo "Python Version: $(pythonVersion)"
#         echo "Short Tag: $(shortPyVer)"
#         echo "Building Universal2 Binary"
#         cd "$(Build.SourcesDirectory)/mssql_python/pybind"
#         # Call build.sh to build the .so file
#         ./build.sh
#       displayName: 'Build .so file'
#       continueOnError: false

#     # Copy the built .so file to staging folder for artifacts
#     - task: CopyFiles@2
#       inputs:
#         SourceFolder: '$(Build.SourcesDirectory)/mssql_python'
#         Contents: '*.so'
#         TargetFolder: '$(Build.ArtifactStagingDirectory)/ddbc-bindings/macOS'
#       displayName: 'Place .so file into artifacts directory'

#     - script: |
#         brew update
#         brew install docker colima

#         # Try VZ first, fallback to QEMU if it fails
#         # Use more conservative resource allocation for Azure DevOps runners
#         colima start --cpu 3 --memory 10 --disk 30 --vm-type=vz || \
#         colima start --cpu 3 --memory 10 --disk 30 --vm-type=qemu

#         # Set a timeout to ensure Colima starts properly
#         sleep 30

#         # Optional: set Docker context (usually automatic)
#         docker context use colima >/dev/null || true

#         # Confirm Docker is operational
#         docker version
#         docker ps
#       displayName: 'Install and start Colima-based Docker'
#       timeoutInMinutes: 15

#     - script: |
#         # Pull and run SQL Server container
#         docker pull mcr.microsoft.com/mssql/server:2022-latest
#         docker run \
#           --name sqlserver \
#           -e ACCEPT_EULA=Y \
#           -e MSSQL_SA_PASSWORD="${DB_PASSWORD}" \
#           -p 1433:1433 \
#           -d mcr.microsoft.com/mssql/server:2022-latest

#         # Starting SQL Server containerâ€¦
#         for i in {1..30}; do
#           docker exec sqlserver \
#             /opt/mssql-tools18/bin/sqlcmd \
#             -S localhost \
#             -U SA \
#             -P "$DB_PASSWORD" \
#             -C -Q "SELECT 1" && break
#           sleep 2
#         done
#       displayName: 'Pull & start SQL Server (Docker)'
#       env:
#         DB_PASSWORD: $(DB_PASSWORD)

#     # Run Pytest to ensure the bindings work correctly
#     - script: |
#         python -m pytest -v
#       displayName: 'Run Pytest to validate bindings'
#       env:
#         DB_CONNECTION_STRING: 'Driver=ODBC Driver 18 for SQL Server;Server=localhost;Database=master;Uid=SA;Pwd=$(DB_PASSWORD);TrustServerCertificate=yes'

#     # Build wheel package for universal2
#     - script: |
#         python -m pip install --upgrade pip
#         pip install wheel setuptools
#         python setup.py bdist_wheel
#       displayName: 'Build $(pythonVersion) universal2 whl'
    
#     # Copy the wheel file to the artifacts
#     - task: CopyFiles@2
#       inputs:
#         SourceFolder: '$(Build.SourcesDirectory)/dist'
#         Contents: '*.whl'
#         TargetFolder: '$(Build.ArtifactStagingDirectory)/dist'
#       displayName: 'Collect wheel package'
    
#     # Publish the collected .so file(s) as build artifacts
#     - task: PublishBuildArtifacts@1
#       condition: succeededOrFailed()
#       inputs:
#         PathtoPublish: '$(Build.ArtifactStagingDirectory)/ddbc-bindings'
#         ArtifactName: 'mssql-python-ddbc-bindings'
#         publishLocation: 'Container'
#       displayName: 'Publish all .so files as artifacts'
    
#     # Publish the collected wheel file(s) as build artifacts
#     - task: PublishBuildArtifacts@1
#       condition: succeededOrFailed()
#       inputs:
#         PathtoPublish: '$(Build.ArtifactStagingDirectory)/dist'
#         ArtifactName: 'mssql-python-wheels-dist'
#         publishLocation: 'Container'
#       displayName: 'Publish all wheels as artifacts'

- job: BuildLinuxWheels
  pool:
    vmImage: 'ubuntu-latest'
  displayName: 'Build Linux -'
  timeoutInMinutes: 120

  strategy:
    matrix:
      py313_arm64_debian:
        pythonVersion: '3.13'
        shortPyVer: '313'
        targetArch: 'arm64'
        dockerPlatform: 'linux/arm64'
        dockerImage: 'debian:12'
        distroName: 'Debian'
        packageManager: 'apt'
      py313_arm64_rhel:
        pythonVersion: '3.13'
        shortPyVer: '313'
        targetArch: 'arm64'
        dockerPlatform: 'linux/arm64'
        dockerImage: 'registry.access.redhat.com/ubi9/ubi:latest'
        distroName: 'RHEL'
        packageManager: 'dnf'
      py310_arm64_alpine:
        pythonVersion: '3.10'
        shortPyVer: '310'
        targetArch: 'arm64'
        dockerPlatform: 'linux/arm64'
        dockerImage: 'alpine:latest'
        distroName: 'alpine'
        packageManager: 'apk'
      py311_arm64_alpine:
        pythonVersion: '3.11'
        shortPyVer: '311'
        targetArch: 'arm64'
        dockerPlatform: 'linux/arm64'
        dockerImage: 'alpine:latest'
        distroName: 'alpine'
        packageManager: 'apk'
      py312_arm64_alpine:
        pythonVersion: '3.12'
        shortPyVer: '312'
        targetArch: 'arm64'
        dockerPlatform: 'linux/arm64'
        dockerImage: 'alpine:latest'
        distroName: 'alpine'
        packageManager: 'apk'
      py313_arm64_alpine:
        pythonVersion: '3.13'
        shortPyVer: '313'
        targetArch: 'arm64'
        dockerPlatform: 'linux/arm64'
        dockerImage: 'alpine:latest'
        distroName: 'alpine'
        packageManager: 'apk'

  steps:
  - script: |
      docker run --rm --privileged multiarch/qemu-user-static --reset -p yes
      docker buildx create --name multiarch --driver docker-container --use || true
      docker buildx inspect --bootstrap
    displayName: 'Setup Docker buildx'

  - script: |
      docker run -d --name build-container-$(distroName)-$(targetArch) \
        --platform $(dockerPlatform) \
        -v $(Build.SourcesDirectory):/workspace \
        -w /workspace \
        --network bridge \
        $(dockerImage) \
        tail -f /dev/null
    displayName: 'Create $(distroName) $(targetArch) container'

  - script: |
      docker run -d --name sqlserver-$(distroName)-$(targetArch) \
        --platform linux/amd64 \
        -e ACCEPT_EULA=Y \
        -e MSSQL_SA_PASSWORD="$(DB_PASSWORD)" \
        -p 1433:1433 \
        mcr.microsoft.com/mssql/server:2022-latest
      
      echo "Waiting for SQL Server to start..."
      for i in {1..60}; do
        if docker exec sqlserver-$(distroName)-$(targetArch) \
          /opt/mssql-tools18/bin/sqlcmd \
          -S localhost \
          -U SA \
          -P "$(DB_PASSWORD)" \
          -C -Q "SELECT 1" >/dev/null 2>&1; then
          echo "SQL Server is ready!"
          break
        fi
        echo "Waiting... ($i/60)"
        sleep 2
      done
      
      docker exec sqlserver-$(distroName)-$(targetArch) \
        /opt/mssql-tools18/bin/sqlcmd \
        -S localhost \
        -U SA \
        -P "$(DB_PASSWORD)" \
        -C -Q "CREATE DATABASE TestDB"
    displayName: 'Start SQL Server container'
    env:
      DB_PASSWORD: $(DB_PASSWORD)

  # Create setup scripts as files to avoid complex escaping
  - script: |
      # Create installation script for Debian
      cat > install_debian.sh << 'EOF'
      #!/bin/bash
      set -e
      export DEBIAN_FRONTEND=noninteractive
      export TZ=UTC
      ln -snf /usr/share/zoneinfo/$TZ /etc/localtime && echo $TZ > /etc/timezone
      
      apt-get update
      apt-get install -y software-properties-common curl wget gnupg build-essential cmake
      
      # Install Python 3.13 from source
      apt-get install -y build-essential libssl-dev zlib1g-dev libbz2-dev \
        libreadline-dev libsqlite3-dev wget curl llvm libncurses5-dev \
        libncursesw5-dev xz-utils tk-dev libffi-dev liblzma-dev \
        libgdbm-dev libnss3-dev libedit-dev
      
      cd /tmp
      wget https://www.python.org/ftp/python/3.13.1/Python-3.13.1.tgz
      tar -xzf Python-3.13.1.tgz
      cd Python-3.13.1
      
      if [ "$(uname -m)" = "aarch64" ]; then
        export CFLAGS="-O1 -g"
        export CXXFLAGS="-O1 -g"
        ./configure --prefix=/usr/local --with-ensurepip=install --enable-loadable-sqlite-extensions
      else
        ./configure --prefix=/usr/local --with-ensurepip=install --enable-loadable-sqlite-extensions --enable-optimizations
      fi
      
      make -j$(nproc)
      make altinstall
      ln -sf /usr/local/bin/python3.13 /usr/local/bin/python
      
      # Install pip
      curl -sS https://bootstrap.pypa.io/get-pip.py | /usr/local/bin/python3.13
      
      # Verify installation
      /usr/local/bin/python3.13 --version
      EOF
      chmod +x install_debian.sh
    displayName: 'Create Debian installation script'
    condition: eq(variables['distroName'], 'Debian')

  - script: |
      # Create installation script for RHEL
      cat > install_rhel.sh << 'EOF'
      #!/bin/bash
      set -e
      
      dnf update -y
      dnf groupinstall -y 'Development Tools'
      dnf install -y wget gnupg2 glibc-devel kernel-headers gcc gcc-c++ make binutils cmake
      dnf install -y openssl-devel bzip2-devel libffi-devel zlib-devel
      
      # Build Python 3.13 from source
      cd /tmp
      wget https://www.python.org/ftp/python/3.13.1/Python-3.13.1.tgz
      tar -xzf Python-3.13.1.tgz
      cd Python-3.13.1
      
      ./configure --prefix=/usr/local --with-ensurepip=install --enable-loadable-sqlite-extensions
      make -j$(nproc)
      make altinstall
      ln -sf /usr/local/bin/python3.13 /usr/local/bin/python
      
      # Verify installation
      /usr/local/bin/python3.13 --version
      EOF
      chmod +x install_rhel.sh
    displayName: 'Create RHEL installation script'
    condition: eq(variables['distroName'], 'RHEL')

  - script: |
      # Create installation script for Alpine
      cat > install_alpine.sh << 'EOF'
      #!/bin/sh
      set -e
      
      apk update
      apk add --no-cache build-base cmake clang git bash wget curl gnupg \
        unixodbc unixodbc-dev libffi-dev openssl-dev zlib-dev patchelf
      
      # Handle Python installation
      PYTHON_VERSION=$1
      
      if [ "$PYTHON_VERSION" = "3.12" ]; then
        # Use pre-installed Python 3.12
        apk add --no-cache py3-pip python3-dev
        ln -sf python3 /usr/bin/python || true
        ln -sf pip3 /usr/bin/pip || true
      else
        # Build from source
        apk add --no-cache tar xz ncurses-dev sqlite-dev readline-dev tk-dev \
          gdbm-dev db-dev bzip2-dev xz-dev linux-headers
        
        cd /tmp
        wget https://www.python.org/ftp/python/${PYTHON_VERSION}.1/Python-${PYTHON_VERSION}.1.tgz
        tar xzf Python-${PYTHON_VERSION}.1.tgz
        cd Python-${PYTHON_VERSION}.1
        
        # Configure for Alpine/musl
        export CFLAGS="-O0 -g"
        export CXXFLAGS="-O0 -g"
        
        ./configure --prefix=/usr/local --enable-shared --with-ensurepip=install \
          --disable-ipv6 --build=aarch64-alpine-linux-musl
        
        # Single-threaded build for stability
        make
        make altinstall
        
        ln -sf /usr/local/bin/python${PYTHON_VERSION} /usr/local/bin/python
        
        # Set up environment
        export PYTHONHOME=/usr/local
        export PYTHONPATH="/usr/local/lib/python${PYTHON_VERSION}"
        export LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH
      fi
      
      python --version
      EOF
      chmod +x install_alpine.sh
    displayName: 'Create Alpine installation script'
    condition: eq(variables['distroName'], 'alpine')

  # Copy and execute the appropriate installation script
  - script: |
      if [ "$(distroName)" = "Debian" ]; then
        docker cp install_debian.sh build-container-$(distroName)-$(targetArch):/tmp/
        docker exec build-container-$(distroName)-$(targetArch) bash /tmp/install_debian.sh
      elif [ "$(distroName)" = "RHEL" ]; then
        docker cp install_rhel.sh build-container-$(distroName)-$(targetArch):/tmp/
        docker exec build-container-$(distroName)-$(targetArch) bash /tmp/install_rhel.sh
      elif [ "$(distroName)" = "alpine" ]; then
        docker cp install_alpine.sh build-container-$(distroName)-$(targetArch):/tmp/
        docker exec build-container-$(distroName)-$(targetArch) sh /tmp/install_alpine.sh $(pythonVersion)
      fi
    displayName: 'Install dependencies in $(distroName) $(targetArch) container'

  # Install ODBC driver
  - script: |
      cat > install_odbc.sh << 'EOF'
      #!/bin/bash
      set -e
      
      PACKAGE_MANAGER=$1
      DISTRO_NAME=$2
      
      if [ "$PACKAGE_MANAGER" = "apt" ]; then
        export DEBIAN_FRONTEND=noninteractive
        if [ "$DISTRO_NAME" = "Ubuntu" ]; then
          curl -sSL -O https://packages.microsoft.com/config/ubuntu/22.04/packages-microsoft-prod.deb
        else
          curl -sSL -O https://packages.microsoft.com/config/debian/12/packages-microsoft-prod.deb
        fi
        dpkg -i packages-microsoft-prod.deb || true
        rm packages-microsoft-prod.deb
        apt-get update
        ACCEPT_EULA=Y apt-get install -y msodbcsql18 mssql-tools18 unixodbc-dev
      elif [ "$PACKAGE_MANAGER" = "apk" ]; then
        case $(uname -m) in
          x86_64) architecture='amd64' ;;
          arm64|aarch64) architecture='arm64' ;;
          *) echo "Unsupported architecture"; exit 1 ;;
        esac
        curl -O https://download.microsoft.com/download/fae28b9a-d880-42fd-9b98-d779f0fdd77f/msodbcsql18_18.5.1.1-1_${architecture}.apk
        curl -O https://download.microsoft.com/download/7/6d/76de322a-d860-4894-9945-f0cc5d6a45f8/mssql-tools18_18.4.1.1-1_${architecture}.apk
        apk add --allow-untrusted msodbcsql18_18.5.1.1-1_${architecture}.apk
        apk add --allow-untrusted mssql-tools18_18.4.1.1-1_${architecture}.apk
        rm -f *.apk
      else
        # RHEL
        curl -sSL -O https://packages.microsoft.com/config/rhel/9/packages-microsoft-prod.rpm
        rpm -Uvh packages-microsoft-prod.rpm
        rm packages-microsoft-prod.rpm
        dnf update -y
        ACCEPT_EULA=Y dnf install -y msodbcsql18 mssql-tools18 unixODBC-devel
      fi
      EOF
      chmod +x install_odbc.sh
      docker cp install_odbc.sh build-container-$(distroName)-$(targetArch):/tmp/
      docker exec build-container-$(distroName)-$(targetArch) bash /tmp/install_odbc.sh $(packageManager) $(distroName)
    displayName: 'Install ODBC Driver'

  # Install Python dependencies and build
  - script: |
      cat > build_package.sh << 'EOF'
      #!/bin/bash
      set -e
      
      # Set up environment for Alpine if needed
      if [ -f /etc/alpine-release ] && [ "$1" != "3.12" ]; then
        export PYTHONHOME=/usr/local
        export PYTHONPATH="/usr/local/lib/python$1"
        export LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH
      fi
      
      # Find Python command
      if command -v /usr/local/bin/python3.13 >/dev/null 2>&1; then
        PYTHON_CMD=/usr/local/bin/python3.13
      elif command -v /usr/local/bin/python$1 >/dev/null 2>&1; then
        PYTHON_CMD=/usr/local/bin/python$1
      elif command -v python3 >/dev/null 2>&1; then
        PYTHON_CMD=python3
      else
        echo "No Python interpreter found"
        exit 1
      fi
      
      echo "Using Python: $PYTHON_CMD"
      $PYTHON_CMD --version
      
      # Create virtual environment
      $PYTHON_CMD -m venv /workspace/venv
      source /workspace/venv/bin/activate
      
      # Install dependencies
      python -m pip install --upgrade pip
      python -m pip install pybind11 wheel setuptools
      python -m pip install -r requirements.txt
      
      # Build the bindings
      cd mssql_python/pybind
      chmod +x build.sh
      ./build.sh
      
      # Build the wheel
      cd /workspace
      python setup.py bdist_wheel
      ls -la dist/
      EOF
      chmod +x build_package.sh
      docker cp build_package.sh build-container-$(distroName)-$(targetArch):/tmp/
      docker exec build-container-$(distroName)-$(targetArch) bash /tmp/build_package.sh $(pythonVersion)
    displayName: 'Build package'

  # Run tests
  - script: |
      SQLSERVER_IP=$(docker inspect sqlserver-$(distroName)-$(targetArch) --format='{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}')
      echo "SQL Server IP: $SQLSERVER_IP"
      
      cat > run_tests.sh << 'EOF'
      #!/bin/bash
      set -e
      
      # Set up environment for Alpine if needed
      if [ -f /etc/alpine-release ] && [ "$1" != "3.12" ]; then
        export PYTHONHOME=/usr/local
        export PYTHONPATH="/usr/local/lib/python$1"
        export LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH
      fi
      
      source /workspace/venv/bin/activate
      
      # Remove system ODBC driver to test with bundled one
      if command -v apt-get >/dev/null 2>&1; then
        apt-get remove --purge -y msodbcsql18 mssql-tools18 unixodbc-dev || true
      elif command -v apk >/dev/null 2>&1; then
        apk del msodbcsql18 mssql-tools18 unixodbc-dev || true
      else
        dnf remove -y msodbcsql18 mssql-tools18 unixODBC-devel || true
      fi
      
      echo "Running tests..."
      python -m pytest -v --junitxml=test-results.xml --cov=. --cov-report=xml:coverage.xml
      EOF
      chmod +x run_tests.sh
      docker cp run_tests.sh build-container-$(distroName)-$(targetArch):/tmp/
      
      docker exec \
        -e DB_CONNECTION_STRING="Driver=ODBC Driver 18 for SQL Server;Server=$SQLSERVER_IP;Database=TestDB;Uid=SA;Pwd=$(DB_PASSWORD);TrustServerCertificate=yes" \
        -e DB_PASSWORD="$(DB_PASSWORD)" \
        build-container-$(distroName)-$(targetArch) bash /tmp/run_tests.sh $(pythonVersion)
    displayName: 'Run tests'
    env:
      DB_PASSWORD: $(DB_PASSWORD)

  # Copy artifacts
  - script: |
      docker cp build-container-$(distroName)-$(targetArch):/workspace/test-results.xml $(Build.SourcesDirectory)/test-results-$(distroName)-$(targetArch).xml || true
      docker cp build-container-$(distroName)-$(targetArch):/workspace/coverage.xml $(Build.SourcesDirectory)/coverage-$(distroName)-$(targetArch).xml || true
      
      mkdir -p $(Build.ArtifactStagingDirectory)/dist
      docker cp build-container-$(distroName)-$(targetArch):/workspace/dist/. $(Build.ArtifactStagingDirectory)/dist/ || true
      
      mkdir -p $(Build.ArtifactStagingDirectory)/ddbc-bindings/linux/$(distroName)-$(targetArch)
      docker cp build-container-$(distroName)-$(targetArch):/workspace/mssql_python/ddbc_bindings.cp$(shortPyVer)-$(targetArch).so $(Build.ArtifactStagingDirectory)/ddbc-bindings/linux/$(distroName)-$(targetArch)/ || true
    displayName: 'Copy artifacts'
    condition: always()

  # Cleanup
  - script: |
      docker stop build-container-$(distroName)-$(targetArch) || true
      docker rm build-container-$(distroName)-$(targetArch) || true
      docker stop sqlserver-$(distroName)-$(targetArch) || true
      docker rm sqlserver-$(distroName)-$(targetArch) || true
    displayName: 'Cleanup'
    condition: always()

  # Publish results
  - task: PublishTestResults@2
    condition: succeededOrFailed()
    inputs:
      testResultsFiles: '**/test-results-$(distroName)-$(targetArch).xml'
      testRunTitle: 'Test results for $(distroName) $(targetArch)'

  - task: PublishBuildArtifacts@1
    condition: succeededOrFailed()
    inputs:
      PathtoPublish: '$(Build.ArtifactStagingDirectory)/ddbc-bindings'
      ArtifactName: 'mssql-python-ddbc-bindings'
      publishLocation: 'Container'

  - task: PublishBuildArtifacts@1
    condition: succeededOrFailed()
    inputs:
      PathtoPublish: '$(Build.ArtifactStagingDirectory)/dist'
      ArtifactName: 'mssql-python-wheels-dist'
      publishLocation: 'Container'
